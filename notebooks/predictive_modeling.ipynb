{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c779c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Task 4: Predictive Modeling for Insurance Risk-Based Pricing\n",
    "# =========================================\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported and directories created successfully!\")\n",
    "\n",
    "# =========================================\n",
    "# Load Data\n",
    "# =========================================\n",
    "df = pd.read_csv('../data/insurance_data.csv')\n",
    "print(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nData Types:\\n{df.dtypes.value_counts()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(f\"Total Premium: R{df['TotalPremium'].sum():,.2f}\")\n",
    "print(f\"Total Claims: R{df['TotalClaims'].sum():,.2f}\")\n",
    "print(f\"Overall Loss Ratio: {(df['TotalClaims'].sum() / df['TotalPremium'].sum()):.4f}\")\n",
    "print(f\"Policies with Claims: {df[df['TotalClaims'] > 0].shape[0]} ({(df[df['TotalClaims'] > 0].shape[0] / len(df) * 100):.2f}%)\")\n",
    "\n",
    "# =========================================\n",
    "# Part 1: Data Preparation\n",
    "# =========================================\n",
    "def prepare_data(df, target_column, exclude_columns=None):\n",
    "    \"\"\"Prepare data for modeling.\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    if 'has_claim' not in data.columns:\n",
    "        data['has_claim'] = (data['TotalClaims'] > 0).astype(int)\n",
    "    \n",
    "    # Feature engineering\n",
    "    if 'RegistrationYear' in data.columns:\n",
    "        data['vehicle_age'] = 2024 - data['RegistrationYear']\n",
    "        data['vehicle_age'] = data['vehicle_age'].clip(0, 50)\n",
    "    \n",
    "    if 'SumInsured' in data.columns and 'TotalPremium' in data.columns:\n",
    "        data['premium_to_sum_insured'] = data['TotalPremium'] / (data['SumInsured'] + 1)\n",
    "    \n",
    "    if 'CustomValueEstimate' in data.columns and 'SumInsured' in data.columns:\n",
    "        data['value_estimate_ratio'] = data['CustomValueEstimate'] / (data['SumInsured'] + 1)\n",
    "    \n",
    "    if 'TotalPremium' in data.columns and 'TotalClaims' in data.columns:\n",
    "        data['expected_loss_ratio'] = data['TotalClaims'] / (data['TotalPremium'] + 1)\n",
    "    \n",
    "    if 'vehicle_age' in data.columns and 'TotalPremium' in data.columns:\n",
    "        data['age_premium_interaction'] = data['vehicle_age'] * data['TotalPremium']\n",
    "    \n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = ['PolicyID', 'TransactionMonth', target_column]\n",
    "    else:\n",
    "        exclude_columns = exclude_columns + [target_column]\n",
    "    \n",
    "    feature_columns = [col for col in data.columns if col not in exclude_columns]\n",
    "    X = data[feature_columns].copy()\n",
    "    y = data[target_column]\n",
    "    \n",
    "    print(f\"Selected {len(feature_columns)} features: {feature_columns}\")\n",
    "    \n",
    "    return X, y, feature_columns\n",
    "\n",
    "def preprocess_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"Preprocess data: handle missing values, encode categorical variables, scale.\"\"\"\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Handle missing values\n",
    "    if len(numerical_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])\n",
    "    \n",
    "    if len(categorical_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\n",
    "    \n",
    "    # Encode categorical\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_processed = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_processed, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, label_encoders\n",
    "\n",
    "# =========================================\n",
    "# Part 2: Claim Severity Prediction\n",
    "# =========================================\n",
    "severity_df = df[df['TotalClaims'] > 0].copy()\n",
    "print(f\"\\nSeverity dataset (policies with claims): {severity_df.shape[0]} policies\")\n",
    "print(f\"Average claim amount: R{severity_df['TotalClaims'].mean():.2f}\")\n",
    "\n",
    "X_sev, y_sev, sev_features = prepare_data(\n",
    "    severity_df,\n",
    "    target_column='TotalClaims',\n",
    "    exclude_columns=['PolicyID','TransactionMonth','has_claim','claim_frequency','claim_severity','margin','loss_ratio']\n",
    ")\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev, scaler_sev, label_encoders_sev = preprocess_data(X_sev, y_sev)\n",
    "\n",
    "# Models\n",
    "severity_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=5),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "results_severity = {}\n",
    "for name, model in severity_models.items():\n",
    "    model.fit(X_train_sev, y_train_sev)\n",
    "    y_pred_train = model.predict(X_train_sev)\n",
    "    y_pred_test = model.predict(X_test_sev)\n",
    "    \n",
    "    results_severity[name] = {\n",
    "        'model': model,\n",
    "        'RMSE_train': np.sqrt(mean_squared_error(y_train_sev, y_pred_train)),\n",
    "        'RMSE_test': np.sqrt(mean_squared_error(y_test_sev, y_pred_test)),\n",
    "        'R2_train': r2_score(y_train_sev, y_pred_train),\n",
    "        'R2_test': r2_score(y_test_sev, y_pred_test),\n",
    "        'MAE_train': mean_absolute_error(y_train_sev, y_pred_train),\n",
    "        'MAE_test': mean_absolute_error(y_test_sev, y_pred_test),\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "\n",
    "severity_comparison = pd.DataFrame([{\n",
    "    'Model': name,\n",
    "    'Test_RMSE': metrics['RMSE_test'],\n",
    "    'Test_R2': metrics['R2_test'],\n",
    "    'Test_MAE': metrics['MAE_test'],\n",
    "    'Train_R2': metrics['R2_train']\n",
    "} for name, metrics in results_severity.items()]).sort_values('Test_R2', ascending=False)\n",
    "\n",
    "best_severity_model_name = severity_comparison.iloc[0]['Model']\n",
    "best_severity_model = results_severity[best_severity_model_name]['model']\n",
    "joblib.dump(best_severity_model, '../models/best_severity_model.pkl')\n",
    "\n",
    "# =========================================\n",
    "# Part 3: Premium Prediction\n",
    "# =========================================\n",
    "X_prem, y_prem, prem_features = prepare_data(\n",
    "    df,\n",
    "    target_column='TotalPremium',\n",
    "    exclude_columns=['PolicyID','TransactionMonth','has_claim','claim_frequency','claim_severity','margin','loss_ratio']\n",
    ")\n",
    "X_train_prem, X_test_prem, y_train_prem, y_test_prem, scaler_prem, label_encoders_prem = preprocess_data(X_prem, y_prem)\n",
    "\n",
    "premium_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=5),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "results_premium = {}\n",
    "for name, model in premium_models.items():\n",
    "    model.fit(X_train_prem, y_train_prem)\n",
    "    y_pred_test = model.predict(X_test_prem)\n",
    "    \n",
    "    percentage_error = np.mean(np.abs((y_test_prem - y_pred_test)/y_test_prem))*100\n",
    "    \n",
    "    results_premium[name] = {\n",
    "        'model': model,\n",
    "        'RMSE_test': np.sqrt(mean_squared_error(y_test_prem, y_pred_test)),\n",
    "        'R2_test': r2_score(y_test_prem, y_pred_test),\n",
    "        'MAE_test': mean_absolute_error(y_test_prem, y_pred_test),\n",
    "        'Percentage_Error': percentage_error\n",
    "    }\n",
    "\n",
    "premium_comparison = pd.DataFrame([{\n",
    "    'Model': name,\n",
    "    'Test_RMSE': metrics['RMSE_test'],\n",
    "    'Test_R2': metrics['R2_test'],\n",
    "    'Test_MAE': metrics['MAE_test'],\n",
    "    'Percentage_Error': metrics['Percentage_Error']\n",
    "} for name, metrics in results_premium.items()]).sort_values('Test_R2', ascending=False)\n",
    "\n",
    "best_premium_model_name = premium_comparison.iloc[0]['Model']\n",
    "best_premium_model = results_premium[best_premium_model_name]['model']\n",
    "joblib.dump(best_premium_model, '../models/best_premium_model.pkl')\n",
    "\n",
    "# =========================================\n",
    "# Part 4: Feature Importance Analysis\n",
    "# =========================================\n",
    "if hasattr(best_severity_model, 'feature_importances_'):\n",
    "    importances = best_severity_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({'Feature': sev_features, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "    feature_importance_df.head(10)\n",
    "\n",
    "# SHAP analysis\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(best_severity_model)\n",
    "    shap_values = explainer(X_test_sev)\n",
    "    shap.summary_plot(shap_values, X_test_sev)\n",
    "except Exception as e:\n",
    "    print(f\"SHAP analysis failed: {e}\")\n",
    "\n",
    "# =========================================\n",
    "# Part 5: Risk-Based Pricing Framework\n",
    "# =========================================\n",
    "avg_claim_freq = df['has_claim'].mean()\n",
    "avg_severity = df[df['TotalClaims']>0]['TotalClaims'].mean()\n",
    "avg_premium = df['TotalPremium'].mean()\n",
    "\n",
    "expense_loading = 0.20\n",
    "profit_margin = 0.10\n",
    "base_risk_premium = avg_claim_freq * avg_severity\n",
    "\n",
    "risk_multipliers = {'Low Risk':0.7, 'Medium Risk':1.0, 'High Risk':1.5}\n",
    "pricing_table = []\n",
    "for seg, mult in risk_multipliers.items():\n",
    "    risk_premium = base_risk_premium * mult\n",
    "    pricing_table.append({\n",
    "        'Risk Segment': seg,\n",
    "        'Recommended Premium': risk_premium*(1+expense_loading+profit_margin),\n",
    "        'Current Avg Premium': avg_premium*mult\n",
    "    })\n",
    "\n",
    "pricing_df = pd.DataFrame(pricing_table)\n",
    "pricing_df.to_csv('../results/risk_based_pricing_framework.csv', index=False)\n",
    "print(pricing_df)\n",
    "\n",
    "# =========================================\n",
    "# Part 6: Evaluation Summary\n",
    "# =========================================\n",
    "print(\"Best Severity Model:\", best_severity_model_name)\n",
    "print(\"Best Premium Model:\", best_premium_model_name)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
